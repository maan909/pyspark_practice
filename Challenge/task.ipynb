{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "from pyspark.sql import SparkSession\n",
    "import pandas as pd\n",
    "from pyspark.sql.types import StructField, StructType, FloatType,StringType, IntegerType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://172.10.10.83:4042\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.5</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>task_dataset</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x23b6c3133d0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#spark sesssion\n",
    "\n",
    "findspark.init()\n",
    "spark=SparkSession.builder.appName('task_dataset').getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating data\n",
    "\n",
    "dataemplyee = [(\"James\",\"10045.0\",\"Smith\",26636.0,\"M\",111),\n",
    "    (\"Michael\",\"Rose\",\"\",42288.0,\"M\",222),\n",
    "    (\"Robert\",\"\",\"Williams\",47114.0,\"M\",333),\n",
    "    (\"Maria\",\"Anne\",\"Jones\",12192.0,\"F\",111),\n",
    "    (\"Jen\",\"Mary\",\"Brown\",80456.0,\"F\",222),\n",
    "    (\"Jas\",\"\",\"Smith\",36634.0,\"M\",111),\n",
    "    (\"Mike\",\"Rose\",\"\",40299.0,\"M\",222),\n",
    "    (\"Roby\",\"\",\"Williams\",42156.0,\"M\",333),\n",
    "    (\"Ancy\",\"\",\"Williams\",42246.0,\"M\",222),\n",
    "    (\"Mary\",\"Anne\",\"Jones\",30002.0,\"F\",111),\n",
    "    (\"Ben\",\"Mary\",\"Brown\",12345.0,\"F\",222),\n",
    "    (\"Black\",\"Mary\",\"Richard\",22345.0,\"F\",333),\n",
    "    (\"Mike2\",\"Rose\",\"\",40299.0,\"M\",2),\n",
    "    (\"Roby2\",\"\",\"Williams\",42156.0,\"M\",3),\n",
    "      ]\n",
    "schemaemp = StructType([\n",
    "    StructField(\"firstname\",StringType(),True), \n",
    "    StructField(\"middlename\",StringType(),True),\n",
    "    StructField(\"lastname\",StringType(),True),\n",
    "    StructField(\"salary\", FloatType(), True), \n",
    "    StructField(\"gender\", StringType(), True), \n",
    "    StructField(\"dep_id\",IntegerType(),True), \n",
    "                        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+--------+-------+------+------+\n",
      "|firstname|middlename|lastname| salary|gender|dep_id|\n",
      "+---------+----------+--------+-------+------+------+\n",
      "|    James|   10045.0|   Smith|26636.0|     M|   111|\n",
      "|  Michael|      Rose|        |42288.0|     M|   222|\n",
      "|   Robert|          |Williams|47114.0|     M|   333|\n",
      "|    Maria|      Anne|   Jones|12192.0|     F|   111|\n",
      "|      Jen|      Mary|   Brown|80456.0|     F|   222|\n",
      "|      Jas|          |   Smith|36634.0|     M|   111|\n",
      "|     Mike|      Rose|        |40299.0|     M|   222|\n",
      "|     Roby|          |Williams|42156.0|     M|   333|\n",
      "|     Ancy|          |Williams|42246.0|     M|   222|\n",
      "|     Mary|      Anne|   Jones|30002.0|     F|   111|\n",
      "|      Ben|      Mary|   Brown|12345.0|     F|   222|\n",
      "|    Black|      Mary| Richard|22345.0|     F|   333|\n",
      "|    Mike2|      Rose|        |40299.0|     M|     2|\n",
      "|    Roby2|          |Williams|42156.0|     M|     3|\n",
      "+---------+----------+--------+-------+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emp_df = spark.createDataFrame(dataemplyee,schema=schemaemp)\n",
    "emp_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   firstname middlename  lastname   salary gender  dep_id\n",
      "0      James    10045.0     Smith  26636.0      M     111\n",
      "1    Michael       Rose            42288.0      M     222\n",
      "2     Robert             Williams  47114.0      M     333\n",
      "3      Maria       Anne     Jones  12192.0      F     111\n",
      "4        Jen       Mary     Brown  80456.0      F     222\n",
      "5        Jas                Smith  36634.0      M     111\n",
      "6       Mike       Rose            40299.0      M     222\n",
      "7       Roby             Williams  42156.0      M     333\n",
      "8       Ancy             Williams  42246.0      M     222\n",
      "9       Mary       Anne     Jones  30002.0      F     111\n",
      "10       Ben       Mary     Brown  12345.0      F     222\n",
      "11     Black       Mary   Richard  22345.0      F     333\n",
      "12     Mike2       Rose            40299.0      M       2\n",
      "13     Roby2             Williams  42156.0      M       3\n"
     ]
    }
   ],
   "source": [
    "emp_pd_df = emp_df.toPandas()\n",
    "print(emp_pd_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sucessfully converted!\n"
     ]
    }
   ],
   "source": [
    "# pd to csv \n",
    "emp_csv = emp_pd_df.to_csv('emp_data.csv', index=False)\n",
    "print(\"sucessfully converted!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading from csv \n",
      "root\n",
      " |-- firstname: string (nullable = true)\n",
      " |-- middlename: string (nullable = true)\n",
      " |-- lastname: string (nullable = true)\n",
      " |-- salary: double (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- dep_id: integer (nullable = true)\n",
      "\n",
      "+---------+----------+--------+-------+------+------+\n",
      "|firstname|middlename|lastname| salary|gender|dep_id|\n",
      "+---------+----------+--------+-------+------+------+\n",
      "|    James|   10045.0|   Smith|26636.0|     M|   111|\n",
      "|  Michael|      Rose|    NULL|42288.0|     M|   222|\n",
      "|   Robert|      NULL|Williams|47114.0|     M|   333|\n",
      "|    Maria|      Anne|   Jones|12192.0|     F|   111|\n",
      "|      Jen|      Mary|   Brown|80456.0|     F|   222|\n",
      "|      Jas|      NULL|   Smith|36634.0|     M|   111|\n",
      "|     Mike|      Rose|    NULL|40299.0|     M|   222|\n",
      "|     Roby|      NULL|Williams|42156.0|     M|   333|\n",
      "|     Ancy|      NULL|Williams|42246.0|     M|   222|\n",
      "|     Mary|      Anne|   Jones|30002.0|     F|   111|\n",
      "|      Ben|      Mary|   Brown|12345.0|     F|   222|\n",
      "|    Black|      Mary| Richard|22345.0|     F|   333|\n",
      "|    Mike2|      Rose|    NULL|40299.0|     M|     2|\n",
      "|    Roby2|      NULL|Williams|42156.0|     M|     3|\n",
      "+---------+----------+--------+-------+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emp_df_1 = spark.read.csv('C:\\spark_training\\Challenge\\emp_data.csv', inferSchema=True, header=True)\n",
    "print(\"reading from csv \")\n",
    "emp_df_1.printSchema()\n",
    "emp_df_1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed Spark DataFrame:\n",
      "+---------+----------+--------+-------+------+------+-----------------+\n",
      "|firstname|middlename|lastname| salary|gender|dep_id|salary_with_bonus|\n",
      "+---------+----------+--------+-------+------+------+-----------------+\n",
      "|    James|   10045.0|   Smith|26636.0|     M|   111|          36636.0|\n",
      "|  Michael|      Rose|    NULL|42288.0|     M|   222|          52288.0|\n",
      "|   Robert|      NULL|Williams|47114.0|     M|   333|          57114.0|\n",
      "|    Maria|      Anne|   Jones|12192.0|     F|   111|          22192.0|\n",
      "|      Jen|      Mary|   Brown|80456.0|     F|   222|          90456.0|\n",
      "|      Jas|      NULL|   Smith|36634.0|     M|   111|          46634.0|\n",
      "|     Mike|      Rose|    NULL|40299.0|     M|   222|          50299.0|\n",
      "|     Roby|      NULL|Williams|42156.0|     M|   333|          52156.0|\n",
      "|     Ancy|      NULL|Williams|42246.0|     M|   222|          52246.0|\n",
      "|     Mary|      Anne|   Jones|30002.0|     F|   111|          40002.0|\n",
      "|      Ben|      Mary|   Brown|12345.0|     F|   222|          22345.0|\n",
      "|    Black|      Mary| Richard|22345.0|     F|   333|          32345.0|\n",
      "|    Mike2|      Rose|    NULL|40299.0|     M|     2|          50299.0|\n",
      "|    Roby2|      NULL|Williams|42156.0|     M|     3|          52156.0|\n",
      "+---------+----------+--------+-------+------+------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# transformation\n",
    "\n",
    "new_emp_df_1 = emp_df_1.withColumn(\"salary_with_bonus\", emp_df_1.salary+10000) \n",
    "print(\"Transformed Spark DataFrame:\") \n",
    "new_emp_df_1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   firstname middlename  lastname   salary gender  dep_id  salary_with_bonus\n",
      "0      James    10045.0     Smith  26636.0      M     111            36636.0\n",
      "1    Michael       Rose      None  42288.0      M     222            52288.0\n",
      "2     Robert       None  Williams  47114.0      M     333            57114.0\n",
      "3      Maria       Anne     Jones  12192.0      F     111            22192.0\n",
      "4        Jen       Mary     Brown  80456.0      F     222            90456.0\n",
      "5        Jas       None     Smith  36634.0      M     111            46634.0\n",
      "6       Mike       Rose      None  40299.0      M     222            50299.0\n",
      "7       Roby       None  Williams  42156.0      M     333            52156.0\n",
      "8       Ancy       None  Williams  42246.0      M     222            52246.0\n",
      "9       Mary       Anne     Jones  30002.0      F     111            40002.0\n",
      "10       Ben       Mary     Brown  12345.0      F     222            22345.0\n",
      "11     Black       Mary   Richard  22345.0      F     333            32345.0\n",
      "12     Mike2       Rose      None  40299.0      M       2            50299.0\n",
      "13     Roby2       None  Williams  42156.0      M       3            52156.0\n"
     ]
    }
   ],
   "source": [
    "new_emp_df_1_pd = new_emp_df_1.toPandas()\n",
    "print(new_emp_df_1_pd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_emp_df_1_csv=new_emp_df_1_pd.to_csv('new_emp_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "parquet=new_emp_df_1.write.mode(\"overwrite\").parquet(\"new_emp_data.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read Parquet into Pandas DataFrame:\n",
      "   firstname middlename  lastname   salary gender  dep_id  salary_with_bonus\n",
      "0      James    10045.0     Smith  26636.0      M     111            36636.0\n",
      "1    Michael       Rose      None  42288.0      M     222            52288.0\n",
      "2     Robert       None  Williams  47114.0      M     333            57114.0\n",
      "3      Maria       Anne     Jones  12192.0      F     111            22192.0\n",
      "4        Jen       Mary     Brown  80456.0      F     222            90456.0\n",
      "5        Jas       None     Smith  36634.0      M     111            46634.0\n",
      "6       Mike       Rose      None  40299.0      M     222            50299.0\n",
      "7       Roby       None  Williams  42156.0      M     333            52156.0\n",
      "8       Ancy       None  Williams  42246.0      M     222            52246.0\n",
      "9       Mary       Anne     Jones  30002.0      F     111            40002.0\n",
      "10       Ben       Mary     Brown  12345.0      F     222            22345.0\n",
      "11     Black       Mary   Richard  22345.0      F     333            32345.0\n",
      "12     Mike2       Rose      None  40299.0      M       2            50299.0\n",
      "13     Roby2       None  Williams  42156.0      M       3            52156.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df_pandas_parquet_read = pd.read_parquet(\"C:\\\\spark_training\\\\Challenge\\\\new_emp_data.parquet\") \n",
    "print(\"Read Parquet into Pandas DataFrame:\") \n",
    "print(df_pandas_parquet_read)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+--------+-------+------+------+-----------------+\n",
      "|firstname|middlename|lastname| salary|gender|dep_id|salary_with_bonus|\n",
      "+---------+----------+--------+-------+------+------+-----------------+\n",
      "|    James|   10045.0|   Smith|26636.0|     M|   111|          36636.0|\n",
      "|  Michael|      Rose|    NULL|42288.0|     M|   222|          52288.0|\n",
      "|   Robert|      NULL|Williams|47114.0|     M|   333|          57114.0|\n",
      "|    Maria|      Anne|   Jones|12192.0|     F|   111|          22192.0|\n",
      "|      Jen|      Mary|   Brown|80456.0|     F|   222|          90456.0|\n",
      "|      Jas|      NULL|   Smith|36634.0|     M|   111|          46634.0|\n",
      "|     Mike|      Rose|    NULL|40299.0|     M|   222|          50299.0|\n",
      "|     Roby|      NULL|Williams|42156.0|     M|   333|          52156.0|\n",
      "|     Ancy|      NULL|Williams|42246.0|     M|   222|          52246.0|\n",
      "|     Mary|      Anne|   Jones|30002.0|     F|   111|          40002.0|\n",
      "|      Ben|      Mary|   Brown|12345.0|     F|   222|          22345.0|\n",
      "|    Black|      Mary| Richard|22345.0|     F|   333|          32345.0|\n",
      "|    Mike2|      Rose|    NULL|40299.0|     M|     2|          50299.0|\n",
      "|    Roby2|      NULL|Williams|42156.0|     M|     3|          52156.0|\n",
      "+---------+----------+--------+-------+------+------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_spark_parquet = spark.createDataFrame(df_pandas_parquet_read)\n",
    "df_spark_parquet.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+--------+-------+------+------+-----------------+\n",
      "|first_name|middlename|lastname| salary|gender|dep_id|salary_with_bonus|\n",
      "+----------+----------+--------+-------+------+------+-----------------+\n",
      "|     James|   10045.0|   Smith|26636.0|     M|   111|          36636.0|\n",
      "|   Michael|      Rose|    NULL|42288.0|     M|   222|          52288.0|\n",
      "|    Robert|      NULL|Williams|47114.0|     M|   333|          57114.0|\n",
      "|     Maria|      Anne|   Jones|12192.0|     F|   111|          22192.0|\n",
      "|       Jen|      Mary|   Brown|80456.0|     F|   222|          90456.0|\n",
      "|       Jas|      NULL|   Smith|36634.0|     M|   111|          46634.0|\n",
      "|      Mike|      Rose|    NULL|40299.0|     M|   222|          50299.0|\n",
      "|      Roby|      NULL|Williams|42156.0|     M|   333|          52156.0|\n",
      "|      Ancy|      NULL|Williams|42246.0|     M|   222|          52246.0|\n",
      "|      Mary|      Anne|   Jones|30002.0|     F|   111|          40002.0|\n",
      "|       Ben|      Mary|   Brown|12345.0|     F|   222|          22345.0|\n",
      "|     Black|      Mary| Richard|22345.0|     F|   333|          32345.0|\n",
      "|     Mike2|      Rose|    NULL|40299.0|     M|     2|          50299.0|\n",
      "|     Roby2|      NULL|Williams|42156.0|     M|     3|          52156.0|\n",
      "+----------+----------+--------+-------+------+------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_transformed_parquet = df_spark_parquet.withColumnRenamed(\"firstname\", \"first_name\")\n",
    "df_transformed_parquet.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted Transformed DataFrame to Pandas:\n"
     ]
    }
   ],
   "source": [
    "df_transformed_pandas_parquet = df_transformed_parquet.toPandas() \n",
    "print(\"Converted Transformed DataFrame to Pandas:\")\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   first_name middlename  lastname   salary gender  dep_id  salary_with_bonus\n",
      "0       James    10045.0     Smith  26636.0      M     111            36636.0\n",
      "1     Michael       Rose      None  42288.0      M     222            52288.0\n",
      "2      Robert       None  Williams  47114.0      M     333            57114.0\n",
      "3       Maria       Anne     Jones  12192.0      F     111            22192.0\n",
      "4         Jen       Mary     Brown  80456.0      F     222            90456.0\n",
      "5         Jas       None     Smith  36634.0      M     111            46634.0\n",
      "6        Mike       Rose      None  40299.0      M     222            50299.0\n",
      "7        Roby       None  Williams  42156.0      M     333            52156.0\n",
      "8        Ancy       None  Williams  42246.0      M     222            52246.0\n",
      "9        Mary       Anne     Jones  30002.0      F     111            40002.0\n",
      "10        Ben       Mary     Brown  12345.0      F     222            22345.0\n",
      "11      Black       Mary   Richard  22345.0      F     333            32345.0\n",
      "12      Mike2       Rose      None  40299.0      M       2            50299.0\n",
      "13      Roby2       None  Williams  42156.0      M       3            52156.0\n"
     ]
    }
   ],
   "source": [
    "print(df_transformed_pandas_parquet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converted into parquet!\n"
     ]
    }
   ],
   "source": [
    "df_transformed_pandas_parquet_1=df_transformed_pandas_parquet.to_parquet(\"final.parquet\")\n",
    "print(\"converted into parquet!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is the spark data frame! \n",
      "+---------+----------+--------+-------+------+------+-----------------+\n",
      "|firstname|middlename|lastname| salary|gender|dep_id|salary_with_bonus|\n",
      "+---------+----------+--------+-------+------+------+-----------------+\n",
      "|    James|   10045.0|   Smith|26636.0|     M|   111|          36636.0|\n",
      "|  Michael|      Rose|    NULL|42288.0|     M|   222|          52288.0|\n",
      "|   Robert|      NULL|Williams|47114.0|     M|   333|          57114.0|\n",
      "|    Maria|      Anne|   Jones|12192.0|     F|   111|          22192.0|\n",
      "|      Jen|      Mary|   Brown|80456.0|     F|   222|          90456.0|\n",
      "|      Jas|      NULL|   Smith|36634.0|     M|   111|          46634.0|\n",
      "|     Mike|      Rose|    NULL|40299.0|     M|   222|          50299.0|\n",
      "|     Roby|      NULL|Williams|42156.0|     M|   333|          52156.0|\n",
      "|     Ancy|      NULL|Williams|42246.0|     M|   222|          52246.0|\n",
      "|     Mary|      Anne|   Jones|30002.0|     F|   111|          40002.0|\n",
      "|      Ben|      Mary|   Brown|12345.0|     F|   222|          22345.0|\n",
      "|    Black|      Mary| Richard|22345.0|     F|   333|          32345.0|\n",
      "|    Mike2|      Rose|    NULL|40299.0|     M|     2|          50299.0|\n",
      "|    Roby2|      NULL|Williams|42156.0|     M|     3|          52156.0|\n",
      "+---------+----------+--------+-------+------+------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (\"Below is the spark data frame! \")\n",
    "df_spark_parquet.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "converted directly from spark to parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "challenge_1=df_spark_parquet.write.mode(\"overwrite\").parquet(\"challenge_file.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "spark to csv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converted to csv sucessfully!\n"
     ]
    }
   ],
   "source": [
    "challenge_2 = df_spark_parquet.write.csv(\"challenge_file.csv\")\n",
    "print (\"converted to csv sucessfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sparkenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
