{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ADVANCED DATAFRAME OPERATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Windowing Functions in Spark\n",
    "\n",
    "Windowing functions in Spark allow you to perform operations on a set of rows that are related to the current row. These functions are useful for tasks such as calculating running totals, moving averages, and ranking.\n",
    "\n",
    "### Types of Window Functions:\n",
    "\n",
    "1. **Ranking Functions**: These functions assign a rank to each row within a partition of a dataset.\n",
    "    - `row_number()`: Assigns a unique number to each row, starting at 1.\n",
    "    - `rank()`: Assigns a rank to each row, with gaps in the ranking for ties.\n",
    "    - `dense_rank()`: Similar to `rank()`, but without gaps in the ranking.\n",
    "\n",
    "2. **Analytical Functions**: These functions perform calculations across a set of rows related to the current row.\n",
    "    - `cume_dist()`: Calculates the cumulative distribution of a value within a partition.\n",
    "    - `percent_rank()`: Calculates the relative rank of a value within a partition.\n",
    "\n",
    "3. **Aggregate Functions**: These functions perform aggregate calculations over a window of rows.\n",
    "    - `sum()`: Calculates the sum of values.\n",
    "    - `avg()`: Calculates the average of values.\n",
    "    - `min()`: Finds the minimum value.\n",
    "    - `max()`: Finds the maximum value.\n",
    "\n",
    "### Example:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, FloatType,TimestampType, LongType, StringType\n",
    "from pyspark.sql.window import Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "findspark.init()\n",
    "spark = SparkSession.builder.appName('windowing_operation').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://172.10.10.83:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.5</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>windowing_operation</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x21cdd319630>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating data\n",
    "\n",
    "dataemplyee = [(\"James\",\"10045.0\",\"Smith\",26636.0,\"M\",111),\n",
    "    (\"Michael\",\"Rose\",\"\",42288.0,\"M\",222),\n",
    "    (\"Robert\",\"\",\"Williams\",47114.0,\"M\",333),\n",
    "    (\"Maria\",\"Anne\",\"Jones\",12192.0,\"F\",111),\n",
    "    (\"Jen\",\"Mary\",\"Brown\",80456.0,\"F\",222),\n",
    "    (\"Jas\",\"\",\"Smith\",36634.0,\"M\",111),\n",
    "    (\"Mike\",\"Rose\",\"\",40299.0,\"M\",222),\n",
    "    (\"Roby\",\"\",\"Williams\",42156.0,\"M\",333),\n",
    "    (\"Ancy\",\"\",\"Williams\",42246.0,\"M\",222),\n",
    "    (\"Mary\",\"Anne\",\"Jones\",30002.0,\"F\",111),\n",
    "    (\"Ben\",\"Mary\",\"Brown\",12345.0,\"F\",222),\n",
    "    (\"Black\",\"Mary\",\"Richard\",22345.0,\"F\",333),\n",
    "    (\"Mike2\",\"Rose\",\"\",40299.0,\"M\",2),\n",
    "    (\"Roby2\",\"\",\"Williams\",42156.0,\"M\",3),\n",
    "      ]\n",
    "schemaemp = StructType([\n",
    "    StructField(\"firstname\",StringType(),True), \n",
    "    StructField(\"middlename\",StringType(),True),\n",
    "    StructField(\"lastname\",StringType(),True),\n",
    "    StructField(\"salary\", FloatType(), True), \n",
    "    StructField(\"gender\", StringType(), True), \n",
    "    StructField(\"dep_id\",IntegerType(),True), \n",
    "                        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "emp_df = spark.createDataFrame(dataemplyee, schema=schemaemp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- firstname: string (nullable = true)\n",
      " |-- middlename: string (nullable = true)\n",
      " |-- lastname: string (nullable = true)\n",
      " |-- salary: float (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- dep_id: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emp_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+--------+-------+------+------+\n",
      "|firstname|middlename|lastname| salary|gender|dep_id|\n",
      "+---------+----------+--------+-------+------+------+\n",
      "|    James|   10045.0|   Smith|26636.0|     M|   111|\n",
      "|  Michael|      Rose|        |42288.0|     M|   222|\n",
      "|   Robert|          |Williams|47114.0|     M|   333|\n",
      "|    Maria|      Anne|   Jones|12192.0|     F|   111|\n",
      "|      Jen|      Mary|   Brown|80456.0|     F|   222|\n",
      "|      Jas|          |   Smith|36634.0|     M|   111|\n",
      "|     Mike|      Rose|        |40299.0|     M|   222|\n",
      "|     Roby|          |Williams|42156.0|     M|   333|\n",
      "|     Ancy|          |Williams|42246.0|     M|   222|\n",
      "|     Mary|      Anne|   Jones|30002.0|     F|   111|\n",
      "|      Ben|      Mary|   Brown|12345.0|     F|   222|\n",
      "|    Black|      Mary| Richard|22345.0|     F|   333|\n",
      "|    Mike2|      Rose|        |40299.0|     M|     2|\n",
      "|    Roby2|          |Williams|42156.0|     M|     3|\n",
      "+---------+----------+--------+-------+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emp_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Ranking functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import row_number,rank,dense_rank,avg,mean,min,max,col,sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "WindowPartition=Window.partitionBy('dep_id').orderBy('salary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+--------+-------+------+------+----------+\n",
      "|firstname|middlename|lastname| salary|gender|dep_id|row_number|\n",
      "+---------+----------+--------+-------+------+------+----------+\n",
      "|    Mike2|      Rose|        |40299.0|     M|     2|         1|\n",
      "|    Roby2|          |Williams|42156.0|     M|     3|         1|\n",
      "|    Maria|      Anne|   Jones|12192.0|     F|   111|         1|\n",
      "|    James|   10045.0|   Smith|26636.0|     M|   111|         2|\n",
      "|     Mary|      Anne|   Jones|30002.0|     F|   111|         3|\n",
      "|      Jas|          |   Smith|36634.0|     M|   111|         4|\n",
      "|      Ben|      Mary|   Brown|12345.0|     F|   222|         1|\n",
      "|     Mike|      Rose|        |40299.0|     M|   222|         2|\n",
      "|     Ancy|          |Williams|42246.0|     M|   222|         3|\n",
      "|  Michael|      Rose|        |42288.0|     M|   222|         4|\n",
      "|      Jen|      Mary|   Brown|80456.0|     F|   222|         5|\n",
      "|    Black|      Mary| Richard|22345.0|     F|   333|         1|\n",
      "|     Roby|          |Williams|42156.0|     M|   333|         2|\n",
      "|   Robert|          |Williams|47114.0|     M|   333|         3|\n",
      "+---------+----------+--------+-------+------+------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emp_df_with_new_row =  emp_df.withColumn(\"row_number\",row_number().over(WindowPartition))\n",
    "emp_df_with_new_row.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+--------+-------+------+------+----+\n",
      "|firstname|middlename|lastname| salary|gender|dep_id|rank|\n",
      "+---------+----------+--------+-------+------+------+----+\n",
      "|    Mike2|      Rose|        |40299.0|     M|     2|   1|\n",
      "|    Roby2|          |Williams|42156.0|     M|     3|   1|\n",
      "|    Maria|      Anne|   Jones|12192.0|     F|   111|   1|\n",
      "|    James|   10045.0|   Smith|26636.0|     M|   111|   2|\n",
      "|     Mary|      Anne|   Jones|30002.0|     F|   111|   3|\n",
      "|      Jas|          |   Smith|36634.0|     M|   111|   4|\n",
      "|      Ben|      Mary|   Brown|12345.0|     F|   222|   1|\n",
      "|     Mike|      Rose|        |40299.0|     M|   222|   2|\n",
      "|     Ancy|          |Williams|42246.0|     M|   222|   3|\n",
      "|  Michael|      Rose|        |42288.0|     M|   222|   4|\n",
      "|      Jen|      Mary|   Brown|80456.0|     F|   222|   5|\n",
      "|    Black|      Mary| Richard|22345.0|     F|   333|   1|\n",
      "|     Roby|          |Williams|42156.0|     M|   333|   2|\n",
      "|   Robert|          |Williams|47114.0|     M|   333|   3|\n",
      "+---------+----------+--------+-------+------+------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emp_df_rank = emp_df.withColumn(\"rank\", rank().over(WindowPartition))\n",
    "emp_df_rank.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+--------+-------+------+------+----------+\n",
      "|firstname|middlename|lastname| salary|gender|dep_id|dense_rank|\n",
      "+---------+----------+--------+-------+------+------+----------+\n",
      "|    Mike2|      Rose|        |40299.0|     M|     2|         1|\n",
      "|    Roby2|          |Williams|42156.0|     M|     3|         1|\n",
      "|    Maria|      Anne|   Jones|12192.0|     F|   111|         1|\n",
      "|    James|   10045.0|   Smith|26636.0|     M|   111|         2|\n",
      "|     Mary|      Anne|   Jones|30002.0|     F|   111|         3|\n",
      "|      Jas|          |   Smith|36634.0|     M|   111|         4|\n",
      "|      Ben|      Mary|   Brown|12345.0|     F|   222|         1|\n",
      "|     Mike|      Rose|        |40299.0|     M|   222|         2|\n",
      "|     Ancy|          |Williams|42246.0|     M|   222|         3|\n",
      "|  Michael|      Rose|        |42288.0|     M|   222|         4|\n",
      "|      Jen|      Mary|   Brown|80456.0|     F|   222|         5|\n",
      "|    Black|      Mary| Richard|22345.0|     F|   333|         1|\n",
      "|     Roby|          |Williams|42156.0|     M|   333|         2|\n",
      "|   Robert|          |Williams|47114.0|     M|   333|         3|\n",
      "+---------+----------+--------+-------+------+------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emp_df_dense_rank = emp_df.withColumn(\"dense_rank\",dense_rank().over(WindowPartition))\n",
    "emp_df_dense_rank.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Aggregation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "AggregationWindow=Window.partitionBy('dep_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+--------+-------+------+------+-------+-------+-------+--------+\n",
      "|firstname|middlename|lastname| salary|gender|dep_id|average|    min|    max|     sum|\n",
      "+---------+----------+--------+-------+------+------+-------+-------+-------+--------+\n",
      "|    Mike2|      Rose|        |40299.0|     M|     2|40299.0|40299.0|40299.0| 40299.0|\n",
      "|    Roby2|          |Williams|42156.0|     M|     3|42156.0|42156.0|42156.0| 42156.0|\n",
      "|    James|   10045.0|   Smith|26636.0|     M|   111|26366.0|12192.0|36634.0|105464.0|\n",
      "|    Maria|      Anne|   Jones|12192.0|     F|   111|26366.0|12192.0|36634.0|105464.0|\n",
      "|      Jas|          |   Smith|36634.0|     M|   111|26366.0|12192.0|36634.0|105464.0|\n",
      "|     Mary|      Anne|   Jones|30002.0|     F|   111|26366.0|12192.0|36634.0|105464.0|\n",
      "|  Michael|      Rose|        |42288.0|     M|   222|43526.8|12345.0|80456.0|217634.0|\n",
      "|      Jen|      Mary|   Brown|80456.0|     F|   222|43526.8|12345.0|80456.0|217634.0|\n",
      "|     Mike|      Rose|        |40299.0|     M|   222|43526.8|12345.0|80456.0|217634.0|\n",
      "|     Ancy|          |Williams|42246.0|     M|   222|43526.8|12345.0|80456.0|217634.0|\n",
      "|      Ben|      Mary|   Brown|12345.0|     F|   222|43526.8|12345.0|80456.0|217634.0|\n",
      "|   Robert|          |Williams|47114.0|     M|   333|37205.0|22345.0|47114.0|111615.0|\n",
      "|     Roby|          |Williams|42156.0|     M|   333|37205.0|22345.0|47114.0|111615.0|\n",
      "|    Black|      Mary| Richard|22345.0|     F|   333|37205.0|22345.0|47114.0|111615.0|\n",
      "+---------+----------+--------+-------+------+------+-------+-------+-------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import avg, min, max, sum, col\n",
    "\n",
    "emp_df_aggregation = emp_df.withColumn(\"average\", avg(col(\"salary\")).over(AggregationWindow)).withColumn(\"min\", min(col(\"salary\")).over(AggregationWindow)).withColumn(\"max\", max(col(\"salary\")).over(AggregationWindow)).withColumn(\"sum\", sum(col(\"salary\")).over(AggregationWindow))\n",
    "emp_df_aggregation.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Analytics Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import lag,lead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+--------+-------+------+------+-------+-------+\n",
      "|firstname|middlename|lastname| salary|gender|dep_id|    Lag|   lead|\n",
      "+---------+----------+--------+-------+------+------+-------+-------+\n",
      "|    Mike2|      Rose|        |40299.0|     M|     2|   NULL|   NULL|\n",
      "|    Roby2|          |Williams|42156.0|     M|     3|   NULL|   NULL|\n",
      "|    Maria|      Anne|   Jones|12192.0|     F|   111|   NULL|26636.0|\n",
      "|    James|   10045.0|   Smith|26636.0|     M|   111|12192.0|30002.0|\n",
      "|     Mary|      Anne|   Jones|30002.0|     F|   111|26636.0|36634.0|\n",
      "|      Jas|          |   Smith|36634.0|     M|   111|30002.0|   NULL|\n",
      "|      Ben|      Mary|   Brown|12345.0|     F|   222|   NULL|40299.0|\n",
      "|     Mike|      Rose|        |40299.0|     M|   222|12345.0|42246.0|\n",
      "|     Ancy|          |Williams|42246.0|     M|   222|40299.0|42288.0|\n",
      "|  Michael|      Rose|        |42288.0|     M|   222|42246.0|80456.0|\n",
      "|      Jen|      Mary|   Brown|80456.0|     F|   222|42288.0|   NULL|\n",
      "|    Black|      Mary| Richard|22345.0|     F|   333|   NULL|42156.0|\n",
      "|     Roby|          |Williams|42156.0|     M|   333|22345.0|47114.0|\n",
      "|   Robert|          |Williams|47114.0|     M|   333|42156.0|   NULL|\n",
      "+---------+----------+--------+-------+------+------+-------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    " \n",
    "emp_df_lag=emp_df.withColumn(\"Lag\", lag(\"salary\", 1).over(WindowPartition)).withColumn(\"lead\", lead(\"salary\", 1).over(WindowPartition))\n",
    "emp_df_lag.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CUME_DIST() v/s percent_rank()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sparkenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
